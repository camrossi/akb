### TO DO: This should be fixed with SSH KEY Autnentication
ansible_user: cisco
ansible_ssh_private_key_file: ${ ssh_private_key }

fabric_type: ${ fabric_type }

#K8S an Crio Version
kube_version: ${k8s_cluster.kube_version}            # This is the versioning number as per Ubuntu Packages. (apt-cache show <package> | grep Version)
OS_Version: "${k8s_cluster.OS_Version}"
crio_version: "${k8s_cluster.crio_version}"

#HA-Proxy and Keepalied Config 
haproxy_image: ${k8s_cluster.haproxy_image}
control_plane_vip: ${k8s_cluster.control_plane_vip}
vip_port: ${k8s_cluster.vip_port}
keepalived_image: ${k8s_cluster.keepalived_image}
keepalived_router_id: ${k8s_cluster.keepalived_router_id}

#Cluster Networking
pod_subnet: ${k8s_cluster.pod_subnet}
cluster_svc_subnet: ${k8s_cluster.cluster_svc_subnet}
external_svc_subnet: ${k8s_cluster.external_svc_subnet}
pod_subnet_v6: ${k8s_cluster.pod_subnet_v6}
cluster_svc_subnet_v6: ${k8s_cluster.cluster_svc_subnet_v6}
external_svc_subnet_v6: ${k8s_cluster.external_svc_subnet_v6}
ingress_ip: ${k8s_cluster.ingress_ip}
visibility_ip: ${k8s_cluster.visibility_ip}
neo4j_ip: ${k8s_cluster.neo4j_ip}
ntp_server: ${k8s_cluster.ntp_server}
time_zone: "${k8s_cluster.time_zone}"

kubeadm_token: ${k8s_cluster.kubeadm_token}

aci_as: ${as}
calico_as:  ${k8s_cluster.local_as}
apic_username : ${controller.username}
apic_cert_name : ${controller.cert_name}
apic_private_key: ${controller.private_key}
apic_oob_ips :  ${controller.oob_ips}
vrf_tenant: ${vrf_tenant}
vrf_name: ${vrf_name}

bgp_peers:
%{ for node in bgp_peers ~}
  - id: ${node.node_id}
    primary_ip: ${split("/",node.ip)[0]}
    primary_ipv6: ${split("/",node.ipv6)[0]}
    rack_id: "${node.rack_id}"
%{ endfor ~}

docker_mirror: ${k8s_cluster.docker_mirror}
bgp_pass: ${bgp_pass}
sandbox_status: ${k8s_cluster.sandbox_status}
http_proxy_status: ${k8s_cluster.http_proxy_status}
%{ if k8s_cluster.http_proxy_status == "on" }
http_proxy: ${k8s_cluster.http_proxy}
https_proxy: ${k8s_cluster.http_proxy}
proxy_env:
    http_proxy: http://${k8s_cluster.http_proxy}
    https_proxy: http://${k8s_cluster.http_proxy}
    HTTP_PROXY: http://${k8s_cluster.http_proxy}
    HTTPS_PROXY: http://${k8s_cluster.http_proxy}
    no_proxy: .${ dns_domain },localhost, ::1, 172.30.0.1, .svc,.cluster.local, apiserver.kube-service-catalog.svc, %{ for node in calico_nodes }${ split("/", node.ip)[0] }, ${ split("/", node.ipv6)[0] }${node.hostname}.${dns_domain}, ${node.hostname}, %{ endfor }${k8s_cluster.pod_subnet}, ${k8s_cluster.cluster_svc_subnet}, ${k8s_cluster.external_svc_subnet}, ${k8s_cluster.control_plane_vip}, ${cidrhost(k8s_cluster.cluster_svc_subnet, 1)} %{ if k8s_cluster.cluster_svc_subnet_v6 != "" },${cidrhost(k8s_cluster.cluster_svc_subnet_v6, 1)}, %{ endif } %{ if k8s_cluster.docker_mirror != "" },${ split(":", k8s_cluster.docker_mirror)[0] } %{ endif } 
    NO_PROXY: .${ dns_domain },localhost, ::1, 172.30.0.1, .svc,.cluster.local, apiserver.kube-service-catalog.svc, %{ for node in calico_nodes }${ split("/", node.ip)[0] }, ${ split("/", node.ipv6)[0] }${node.hostname}.${dns_domain}, ${node.hostname}, %{ endfor }${k8s_cluster.pod_subnet}, ${k8s_cluster.cluster_svc_subnet}, ${k8s_cluster.external_svc_subnet}, ${k8s_cluster.control_plane_vip}, ${cidrhost(k8s_cluster.cluster_svc_subnet, 1)} %{ if k8s_cluster.cluster_svc_subnet_v6 != "" },${cidrhost(k8s_cluster.cluster_svc_subnet_v6, 1)}, %{ endif } %{ if k8s_cluster.docker_mirror != "" },${ split(":", k8s_cluster.docker_mirror)[0] } %{ endif } 
%{else}
proxy_env: {}
http_proxy: ""
https_proxy: ""
%{endif}
dns_domain: ${dns_domain}
ubuntu_apt_mirror: ${k8s_cluster.ubuntu_apt_mirror}
eBPF_status: ${k8s_cluster.eBPF_status}
